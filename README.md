# Web Crawler
Web Crawler is a Node.js-based application that allows you to extract data from websites. This application can be used to scrape large amounts of data from multiple websites and store the data in a structured format for analysis or further use. It is useful for anyone who needs to gather data from the web for research, marketing, or other purposes.



## Installation
Clone this repository onto your local machine using the following command:

```bash
git clone https://github.com/Sauradip07/webcrawlerhttp.git

cd webcrawlerhttp

npm i

#run the test command to test every thing is fine or not
npm test

npm start httos://example.com
#for example
npm start https://wagslane.dev

```

## Usage

```python
import foobar

# returns 'words'
foobar.pluralize('word')

# returns 'geese'
foobar.pluralize('goose')

# returns 'phenomenon'
foobar.singularize('phenomena')
```

## Contributing

Pull requests are welcome. For major changes, please open an issue first
to discuss what you would like to change.

Please make sure to update tests as appropriate.

## License

[MIT](https://choosealicense.com/licenses/mit/)
